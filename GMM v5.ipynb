{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:04872ecbf918b4afc7f3e278da0970af9c81439aea92eef6213f37105be01b72"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Base.Test\n",
      "using IPynbToJl\n",
      "ipynb_to_jl(\"GMM.ipynb\")\n",
      "ipynb_to_jl(\"logsumexp.ipynb\")\n",
      "ipynb_to_jl(\"LowerTriangular.ipynb\")\n",
      "\n",
      "@printf(\"julia version = %s, dir %s\\n\", Base.VERSION_STRING, pwd())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wrote GMM.jl\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Wrote logsumexp.jl\n",
        "Wrote LowerTriangular.jl\n",
        "julia version = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.4.0-dev, dir C:\\dev\\GitHub\\autodiff\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include(\"MatVec.jl\")\n",
      "include(\"LowerTriangular.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "An example lower triangle made from diag and LT=\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "["
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.1 0.0 0.0 0.0\n",
        " 21.0 2.2 0.0 0.0\n",
        " 31.0 32.0 3.3 0.0\n",
        " 41.0 42.0 43.0 4.4]\n",
        "packed="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "([1.1,2.2,3.3,4.4],\n",
        "[21.0 31.0 32.0 41.0 42.0 43.0])\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------\n",
      "\n",
      "Log-parameterized GMM\n",
      "=====================\n",
      "\n",
      "This is a GMM parameterized by log-weights, and the Cholesky factor of the inverse covariance.  This means we can do unconstrained optimization, and in fact makes for a more efficient computation of the normalization constant, as well as more numerical stability all round.    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##########################################################################\n",
      "# Log-parametrized GMM.\n",
      "# Weights are strictly positive, covariances are parameterized by their inverse\n",
      "# square roots (lower triangular).\n",
      "type lpGMM\n",
      "  n::Int           # number of Gaussians\n",
      "  d::Int           # dimension of Gaussian\n",
      "  alphas::Vec      # log weights: n\n",
      "  mus::Array{Vec}  # means: n, each dx1\n",
      "  qs::Array{Vec}  # square-root-inverse-covariances, log(diagonal): n, each d x 1\n",
      "  Ls::Array{Vec}  # square-root-inverse-covariances, lower triangle: n, each d*(d-1)/2 x 1\n",
      "end\n",
      "\n",
      "# Convert simple GMM to lpGMM\n",
      "function lpGMM(g::GMM)\n",
      "  Ls = Array{Vec}(g.n)\n",
      "  qs = Array{Vec}(g.n)\n",
      "  for k=1:g.n\n",
      "    L = inv(chol(g.sigmas[k].data, Val{:L}))\n",
      "    q, L = ltri_pack(L)\n",
      "    qs[k], Ls[k] = vec(log(q)), vec(L)\n",
      "  end\n",
      "  lpGMM(g.n,g.d,log(g.alphas),g.mus,qs,Ls)\n",
      "end\n",
      "\n",
      "# Convert log-parameterized-GMM to simple GMM UnivariateGMM\n",
      "function GMM(l::lpGMM)\n",
      "  alphas::Vec = exp(l.alphas)/sum(exp(l.alphas))\n",
      "  mus::Array{Vec} = l.mus\n",
      "  Qs = [ltri_unpack(exp(l.qs[i]), l.Ls[i]) for i=1:l.n]\n",
      "  sigmas::Array{SymMat} = map(A->inv(Symmetric(A'*A)), Qs)\n",
      "  GMM(l.n,l.d,alphas,mus,sigmas)\n",
      "end\n",
      "\n",
      "g = lpGMM(test_gmm)\n",
      "@printf(\"testgmm=%s\\n**\\n\", test_gmm)\n",
      "@printf(\"gmm=%s\\n**\\n\", GMM(g))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "testgmm="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GMM(3,2,[0.19310431615207277,0.5364502840070069,0.27044539984092036],[[0.7119158688357681,-0.25671733787901185],[-1.103907085941275,-0.04054827781196816],[-0.10109551328225508,0.9670873884555917]],[\n",
        "[3.4529280599940937 1.9270622270819473\n",
        " 1.9270622270819473 1.0786637824461467],\n",
        "\n",
        "[1.6020180059525686 1.469170726684045\n",
        " 1.469170726684045 2.329098032854807],\n",
        "\n",
        "[6.426174220227761 -0.8472742009765244\n",
        " -0.8472742009765244 0.35890549388218623]])\n",
        "**\n",
        "gmm=GMM(3,2,[0.19310431615207277,0.5364502840070069,0.27044539984092036],[[0.7119158688357681,-0.25671733787901185],[-1.103907085941275,-0.04054827781196816],[-0.10109551328225508,0.9670873884555917]],[\n",
        "[3.452928059994131 1.927062227081968\n",
        " 1.927062227081968 1.0786637824461582],\n",
        "\n",
        "[1.6020180059525684 1.4691707266840448\n",
        " 1.4691707266840448 2.3290980328548065],\n",
        "\n",
        "[6.426174220227762 -0.8472742009765245\n",
        " -0.8472742009765245 0.3589054938821863]])\n",
        "**\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test it a bit\n",
      "\n",
      "n=3\n",
      "d=2\n",
      "alphas=rand(n); alphas /= sum(alphas);\n",
      "mus=[randn(d) for k=1:n]\n",
      "sigmas=[AAt(randn(d,d)) for k=1:n]\n",
      "test_gmm = GMM(n,d,alphas,mus,sigmas)\n",
      "@printf(\"An example gmm = %s\\n\", test_gmm)\n",
      "\n",
      "x = randn(d) # Test point\n",
      "\n",
      "ll0 = log_likelihood(test_gmm, x)\n",
      "@printf(\"Tes log likelihood ll0=%f\\n\", ll0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "An example gmm = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GMM(3,2,[0.19310431615207277,0.5364502840070069,0.27044539984092036],"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0.7119158688357681,-0.25671733787901185],[-1.103907085941275,-0.04054827781196816],[-0.10109551328225508,0.9670873884555917]],[\n",
        "["
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.4529280599940937 1.9270622270819473\n",
        " 1.9270622270819473 1.0786637824461467],\n",
        "\n",
        "[1.6020180059525686 1.469170726684045\n",
        " 1.469170726684045 2.329098032854807],\n",
        "\n",
        "[6.426174220227761 -0.8472742009765244\n",
        " -0.8472742009765244 0.35890549388218623]])\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tes log likelihood ll0=-3.572386\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "lpGMM log-likelihood\n",
      "--------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "const halflog2\u03c0 = log(2\u03c0)/2\n",
      "\n",
      "# Compute log-likelihood\n",
      "# This version is easy to read, but we can do better (see below)\n",
      "function log_likelihood_reference(g::lpGMM, x::Vec)\n",
      "  total = 0\n",
      "  weights = exp(g.alphas)\n",
      "  weights /= sum(weights) \n",
      "  for k=1:g.n\n",
      "    L_diagonal = exp(g.qs[k])\n",
      "    L_ltri_entries = g.Ls[k] \n",
      "    InvLowerTriangle = ltri_unpack(L_diagonal, L_ltri_entries)\n",
      "    mean = g.mus[k]\n",
      "    mahalanobis = sumsq(InvLowerTriangle * (mean - x))\n",
      "    total += weights[k] * det(InvLowerTriangle) * exp(-0.5*mahalanobis)\n",
      "  end\n",
      "  log(total) - halflog2\u03c0*g.d\n",
      "end\n",
      "\n",
      "ll1 = log_likelihood_reference(g, x)\n",
      "@printf(\"ll0=%f, ll1=%f, ratio to true=%f\\n\", ll0, ll1, ll0/ll1)\n",
      "@test_approx_eq_eps ll0 ll1 1e-12\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ll0="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-3.572386, ll1=-3.572386, ratio to true=1.000000\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "include(\"logsumexp.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "logsumexp: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.134967 = 2.134967\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "logsumexp_both (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Cleanest log_likelihood implementation\n",
      "function log_likelihood(g::lpGMM, x::Vec)\n",
      "    # function to combine log-diagonal an lower triangle\n",
      "    get_Q(L_log_diagonal, L_ltri_entries) = ltri_unpack(exp(L_log_diagonal), L_ltri_entries)\n",
      "\n",
      "    # mahalanobis distances squared\n",
      "    d_mahals = [0.5*sumsq(get_Q(g.qs[i], g.Ls[i])*(g.mus[i] - x)) for i in 1:g.n]\n",
      "    \n",
      "    # log determinants\n",
      "    log_determinants = [sum(g.qs[i]) for i in 1:g.n]\n",
      "    \n",
      "    logsumexp(g.alphas + log_determinants - d_mahals) - logsumexp(g.alphas) - halflog2\u03c0*g.d\n",
      "end\n",
      "\n",
      "ll2 = log_likelihood(g, x)\n",
      "@printf(\"ll0=%f, ll2=%f, ratio to true=%f\\n\", ll0, ll2, ll0/ll2)\n",
      "@test_approx_eq_eps ll0 ll2 1e-12\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ll0="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-3.572386, ll2=-3.572386, ratio to true=1.000000\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}